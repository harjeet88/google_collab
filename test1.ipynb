{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1yKjj6ZPGjL_zB5MgcPFuW65CdrUbJIrx",
      "authorship_tag": "ABX9TyPcJTogvISL8EuE57Cl0Ngk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harjeet88/google_collab/blob/main/test1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Nrfmk5PKyD2P"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --user delta\n",
        "!pip install --user findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvaT8IajyMs9",
        "outputId": "6f71bf17-0c17-4bab-e644-71b89773df13"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: delta in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: findspark in /usr/local/lib/python3.10/dist-packages (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"drive/MyDrive/colab_install/spark-3.5.1-bin-hadoop3\"\n",
        "os.environ[\"PYSPARK_PYTHON\"] = \"python3\"\n",
        "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python3\"\n",
        "!chmod +x -R drive/MyDrive/colab_install/spark-3.5.1-bin-hadoop3/*\n"
      ],
      "metadata": {
        "id": "j0Lnbzw5yUyC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "O9AHEJLHyYNp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "MAX_MEMORY=\"8g\"\n",
        "maven_coords = [\n",
        "    \"org.apache.spark:spark-avro_2.12:3.2.1\",\n",
        "    \"io.delta:delta-core_2.12:2.0.0rc1\",\n",
        "    \"org.xerial:sqlite-jdbc:3.36.0.3\",\n",
        "    \"graphframes:graphframes:0.8.2-spark3.2-s_2.12\",\n",
        "    \"com.acervera.osm4scala:osm4scala-spark3-shaded_2.12:1.0.8\",\n",
        "]\n",
        "\n",
        "spark = (pyspark.sql.SparkSession.builder.appName(\"MyApp\")\n",
        "    .config(\"spark.jars.packages\", \",\".join(maven_coords))\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        "    .config(\"spark.executor.memory\", MAX_MEMORY)\n",
        "    .config(\"spark.driver.memory\", MAX_MEMORY)\n",
        "    .enableHiveSupport()\n",
        "    .getOrCreate()\n",
        "    )"
      ],
      "metadata": {
        "id": "9Z0uH9XIybQx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "RUGemWhPykrI",
        "outputId": "1a12d6d5-0fa5-477f-cbda-486570d82a9d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7c8c7cb0c700>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - hive</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://fe63a696d046:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>MyApp</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!save my_environment.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfF6vJo71Qcm",
        "outputId": "cc873188-eba2-491e-ebc0-e2804722f82d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: save: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8CU9YX5Q1TOZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}